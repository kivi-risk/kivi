---

### 1. 逻辑回归 Theory 

#### 1.1 风控与评分卡

信用评分卡模型是最常见的金融风控手段之一，它是指根据客户的各种属性和行为数据，
利用一定的信用评分模型，对客户进行信用评分。

按照借贷用户的借贷时间，评分卡模型可以划分为以下三种：

1. 贷前：申请评分卡（Application score card），又称为A卡
1. 贷中：行为评分卡（Behavior score card），又称为B卡
1. 贷后：催收评分卡（Collection score card），又称为C卡

#### 1.2 逻辑回归

**逻辑回归本身具有良好的校准度，其输出概率与真实概率之间存在良好的一致性。**
因此，我们也就可以直接把概率分数线形映射为整数分数。

将客户违约的概率表示为p，则正常的概率为1-p。
$$
p(y=1|\theta,\ X+b) = \frac{1}{1+e^{-\theta^TX+b}}
$$
整理以上公式：
$$
log(\frac{p}{1-p}) = \theta^TX+b
$$

定义：

$$
define
\begin{cases}
A>0,\ B>0 \\\\
odds = \frac{p}{1-p}
\end{cases}
$$

将 $odds$ 带入逻辑回归函数可得：
$$
log(odds) = \theta^TX+b
$$

评分卡的分值可以定义为比率对数的线性表达来，即：
$$
\begin{aligned}
Score & = A-B\times log(odds)\\\\
& = A-B[\theta^TWoe(X)+b]
\end{aligned}
$$

其中`A`与`B`是常数，通常将常数A称为补偿，常数B称为刻度。
`B`前面的负号可以使得违约概率越低，得分越高。
通常情况下，即高分值代表低风险，低分值代表高风险。`A`、`B`的值可以
通过将两个已知或假设的分值带入计算得到。通常情况下，需要设定三个假设（参数）：

1. `基准Odds`：与真实违约概率一一对应，可换算得到违约概率。
2. `基准分数`：某个特定的违约概率下的预期评分，即比率`Odds`为 $\theta_0$ 
时的分数为 $P_0$。
2. `PDO`(Points to Double the Odds)：该违约概率翻倍的评分，即
`Odds`（坏好比）变成2倍时，所减少的信用分。

解出$A$和$B$:

$$
\begin{aligned}
Base\\_score & = A - B\times ln(Odds_0), \\\\
Base\\_score - PDO & = A - B\times ln(2Odds_0)\\\\
B & = \frac{PDO}{ln2} \\\\
A & = Base\\_score + B\times ln(Odds_0) \\\\
\end{aligned}
$$

在实际的应用中，我们会计算出每个变量的各分箱对应的分值。
新用户产生时，对应到每个分箱的值，将这些值相加，最后加上初始基础分，
得到最终的结果。

$$
Score = A - B{\theta_0 + \theta_1x_1 + ... + \theta_nx_n}
$$


### 样本建设

#### 基本样本建设的流程

#### 样本检查内容

1. 违约迁徙
2. 违约标签
3. 观察期
4. 表现期
5. 



### 2. 评分卡建设实践

**以下，采用自动化评分卡构建工具 kivi 进行数据分析及评分卡的构建；以下数据仅作为示例展示，不具备实际的指导意义。**

> 模拟数据

```python
from kivi import WOE
from kivi.Dataset import *
from kivi.FeatureAnalysis import *

# 载入数据
df_bank = Dataset.BankData()

# 选择数值型变量
df_bank = df_bank.select_dtypes(include=['int64', 'float64']).copy()
```



#### 2.1 指标自动分箱

##### 2.1.1 自动分箱

**一般这里默认选择自动的决策树分箱。分箱数量自5箱（不含空箱）递减至2箱，直至分箱`WOE`单调递增或者单调递减。**

```python
df_woe, fault_cols = WOE.WOEBatchWithRebin(df_bank, drop_columns=['target'])
```

- `df_woe`: 全量的分箱结果。
- `fault_cols`: 分箱失败的字段名称；可能是由于数据异常导致，可以通过该变量检查分箱失败的字段的具体数据。

<center>
<img src="./img/woe.png" width="680">
<br>
<div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">上图为分箱结果示例</div>
</center>

##### 2.1.2 分箱的效果分析

> 分箱单调性

分箱`WOE`排序尽量单调；对于不单调的变量，要判断指标的拐点是否符合经济含义，在实际应用中，不单调变量的风险拐点在未来时间上可能会出现偏移，影响模型效果。

**1. 单调递增：**
  - 示例1：如企业存款分数为`[0, 10, 50, 80, 90, 100]`，一般认为符合经济含义。
  - 示例2：如企业存款分数为`[0, 10, 50, 50, 90, 100]`，基本认为符合经济含义，但由于有两箱分数均为50分，需要合并分箱或重分箱。
**2. 单调递减：**
  - 示例1：如企业历史违约次数指标分数值为`[100, 80, 50, 40, 10, 0]`，一般认为符合经济含义。
**3. 先增后减：**
  - 示例1：如企业主年龄分数值为`[0, 50, 100, 80, 50, 0]`，一般认为符合经济含义，但此时需要关注`100`分下的年龄是多少，
  一般认为在`25-45`之间比较符合风险直觉，而且需要考虑这个峰值拐点在未来是否会偏移。
**4. 先减后增：**
  - 示例1：判断同先增后减。

> 分箱区分能力

1. 要注意空箱的分值不能太高，因为客户指标为`Nan`时，我们没有获取到客户的信息，在没有实际依据的时候从审慎的角度不能给予过高的分数。
2. 要注意比率型指标空箱的含义是否正确。如果空箱含义比较多时，可以分模型进行建模，也可以对空箱再进行进一步的拆分，比如资产负债率指标：
   - 负债 / 资产；在负债为`NULL`或者资产为`NULL`的情况下输出`NULL`。
   - 这时需要确定的是，`NULL`实际代表负债为`NULL`，还是资产为`NULL`，在资产为`NULL`时一般认为资质比较差，但是在负债为`NULL`是一般资质可能比较好，这时考虑在有负债、有资产的客群上考虑该类型指标的效果。
3. 在长周期的指标上考虑长周期的违约概率。
4. 同一类型的指标，应当指示相同的经济含义，比如说，“担保”多，说明信用多，从而违约低，但从另一个角度上讲，担保多代表敞口大，违约的概率低，此类指标容易说不清。另外，不建议直接使用规模类的指标，比如贷款多说明信用多，但一定程度上贷款多也增加了违约的可能性。
5. 应当关注同一类型指标的各个分箱分值是否统一，是否有冲突。

##### 2.1.3 将指标值转换为指标`WOE`值或者`分数值`

在实际数据建模中，一般使用`WOE`值或者`分箱分数值`作为入模指标，因此需要将指标数据转换为`WOE`值或者`分箱分数值`。

```python
# 指标值转换为 WOE 分数值
df_bank['uuid'] = np.arange(0, len(df_bank))
df_val = WOE.TransToWOEVal(df_bank, df_woe, values='score', batch=3)
```

<center>
    <figure class="half">
        <img src="./img/score_val.png" height="160">
        <img src="./img/row_val.png" height="160">
    </figure>
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">上图左为指标原值，右为指标分数值</div>
</center>

#### 2.2 指标效果单变量分析

在进行了指标的原值转换为分数值之后，需要进一步分析指标对于目标预测变量的区分效果，因此在该步骤进行指标分数值的单变量回归。

```python
df_res = StatsUnivariate(df_val)
df_res[['var_name', 'missing', 'ks', 'auc']]
```

```python
|    | var_name   |   missing |        ks |      auc |
|---:|:-----------|----------:|----------:|---------:|
|  0 | campaign   |         0 | 0.0871526 | 0.558636 |
|  1 | duration   |         0 | 0.478635  | 0.809791 |
|  2 | previous   |         0 | 0.195167  | 0.600225 |
|  3 | age        |         0 | 0.0862682 | 0.543134 |
|  4 | balance    |         0 | 0.134203  | 0.567102 |
|  5 | day        |         0 | 0.0401636 | 0.520082 |
|  6 | pdays      |         0 | 0.194578  | 0.597289 |
```

**在此，主要以 KS 和 AUC 评估指标的区分效果。**

#### 2.3 指标重分箱

在实际建模的过程中，自动分箱的结果不一定会满足指标实际含义的解释，因此需要进一步的重分箱分析 。

> 单个指标的重分箱

```python
WOE.Rebins(
    col_name='age', target_name='target',
    df=df_bank, bins=[-np.inf, 30, 50, np.inf])
```

<center>
<img src="./img/mon_rebin.png" width="780">
    <br>
    <div style="color:orange; border-bottom: 1px solid #d9d9d9;
    display: inline-block;
    color: #999;
    padding: 2px;">单个指标分箱方法示例，主要用于单个指标的分箱分析</div>
</center>

> 批量指标的重分箱

```python
bins = {
    'col_a': [-np.inf, 40, 60, 100, np.inf],
    'col_b': [-np.inf, 20, 60, 90, np.inf],
    'col_c': [-np.inf, 90, 60, 800, np.inf],
}

columns_name = ['col_a', 'col_b', 'col_c']
df_rebins, _ = WOEBatch(df_train, columns_name, target='target', WOEFun=CutOffPoint, bins=bins)
```

`df_rebins` 即为指标`['col_a', 'col_b', 'col_c']`重分箱后的分箱结果。

> 重分箱结果与原分箱结果进行合并

```python
df_woe = WOE.AppendRebinWoe(df_woe, df_rebins)
```

**切记，由于在重分箱之后分箱结果有了变化，因此需要再进行一次“指标分数转换”将指标原值按照重分箱之后的分分箱截断点重新进行指标值的转换。**

#### 2.4 模型拟合

##### 2.4.1 模型指标的选择

> 指标的相关性

一般建模过程中会剔除相关性较大的指标，相关性较大的阈值可以在`[0.6 1.0]`之间，可以根据实际数据情况进行选取。

**Pearson 相关系数**

```python
df_val.corr()
```

```bash
|          |   campaign |   duration |   previous |     target |        age |     balance |         day |      pdays |
|:---------|-----------:|-----------:|-----------:|-----------:|-----------:|------------:|------------:|-----------:|
| campaign |  1         |  0.142705  |  0.121869  | -0.0732294 |  0.0487464 |  0.0478219  |  0.153741   |  0.12747   |
| duration |  0.142705  |  1         |  0.0329339 | -0.328743  |  0.0467397 |  0.0680724  |  0.0693767  |  0.0320377 |
| previous |  0.121869  |  0.0329339 |  1         | -0.168056  |  0.0435077 |  0.0738361  |  0.098347   |  0.965694  |
| target   | -0.0732294 | -0.328743  | -0.168056  |  1         | -0.121674  | -0.0857089  | -0.0262861  | -0.162725  |
| age      |  0.0487464 |  0.0467397 |  0.0435077 | -0.121674  |  1         |  0.0637249  |  0.0174265  |  0.0526933 |
| balance  |  0.0478219 |  0.0680724 |  0.0738361 | -0.0857089 |  0.0637249 |  1          |  0.00724705 |  0.0766253 |
| day      |  0.153741  |  0.0693767 |  0.098347  | -0.0262861 |  0.0174265 |  0.00724705 |  1          |  0.099607  |
| pdays    |  0.12747   |  0.0320377 |  0.965694  | -0.162725  |  0.0526933 |  0.0766253  |  0.099607   |  1         |
```

**spearman 相关系数**

`Spearman` 秩相关系数是两个数据集之间关系单调性的非参数度量。
与 `Pearson` 相关性不同，`Spearman` 相关性不假设两个数据集都是正态分布的。
Spearman 系数在 `-1` 和 `+1` 之间变化，`0` 表示没有相关性。
`-1` 或 `+1` 的相关性意味着精确的单调关系。正相关意味着随着 `x` 的增加，`y` 也会增加。
负相关意味着随着 `x` 增加，`y` 减少。

- `p` 值粗略地表示不相关系统生成具有 `Spearman` 相关性的数据集的概率，
- `p` 值并不完全可靠，但对于大于 `500` 左右的数据集可能是合理的。

```python
df_corr = spearmanr(df_val, columns=df_val.columns)
```

```bash
| col_a    |         age |     balance |          day |    duration |      pdays |    previous |      target |
|:---------|------------:|------------:|-------------:|------------:|-----------:|------------:|------------:|
| age      | nan         |   0.0637249 |   0.0174265  | nan         |  0.0526933 | nan         | nan         |
| balance  | nan         | nan         |   0.00724705 | nan         |  0.0766253 | nan         | nan         |
| campaign |   0.0466373 |   0.0486208 |   0.130773   |   0.0705668 |  0.140952  |   0.13728   |  -0.0709507 |
| day      | nan         | nan         | nan          | nan         |  0.099607  | nan         | nan         |
| duration |   0.0484242 |   0.0773014 |   0.0704884  | nan         |  0.0351019 |   0.0339869 |  -0.35886   |
| previous |   0.0487993 |   0.075179  |   0.0984348  | nan         |  0.983441  | nan         |  -0.165675  |
| target   |  -0.121674  |  -0.0857089 |  -0.0262861  | nan         | -0.162725  | nan         | nan         |
```

> 指标的共线性

在多指标的选择中也要考虑指标之间的共线性问题，通常采用`VIF`测度指标之间的共线性程度，一般认为`VIF>10`指标之间存在较大的共线性问题，
最好将指标的共线性控制在`VIF < 5`以内。

```python
# 计算 df_val 中全量指标的 VIF
vif_dict = VIF.StatsTableVIF(df_val)
```

```bash
|    | feature   |   vif_value |
|---:|:----------|------------:|
|  0 | campaign  |     1.73686 |
|  1 | duration  |     3.77668 |
|  2 | previous  |    95.0685  |
|  3 | target    |     1.17446 |
|  4 | age       |     8.00949 |
|  5 | balance   |     2.02765 |
|  6 | day       |     1.68773 |
|  7 | pdays     |    81.3612  |
```

> 依次剔除降低`VIF`最大的指标

```python
df_vif = VIF.LowVIFFeatures(df_val, 3)
```

```bash
|    | feature   |   step_1 |    step_2 |    step_3 |    step_4 |
|---:|:----------|---------:|----------:|----------:|----------:|
|  0 | campaign  |  1.73686 |   1.73686 |   1.72641 |   1.6553  |
|  1 | duration  |  3.77668 |   3.74118 |   2.96156 |   2.25033 |
|  2 | previous  | 95.0685  | nan       | nan       | nan       |
|  3 | target    |  1.17446 |   1.17093 |   1.08487 |   1.05682 |
|  4 | age       |  8.00949 |   7.32035 | nan       | nan       |
|  5 | balance   |  2.02765 |   2.02565 |   1.92176 |   1.74675 |
|  6 | day       |  1.68773 |   1.68606 |   1.6664  |   1.58283 |
|  7 | pdays     | 81.3612  |   5.07071 |   3.43797 | nan       |
```

**剔除顺序**

1. 剔除指标：`previous`
2. 剔除指标：`age`
3. 剔除指标：`pdays`

最终将`VIF`降低到3以内。

##### 2.4.2 多指标模型拟合

```python
columns = ['campaign', 'duration', 'previous', 'age', 'balance', 'day', 'pdays']
model = StatsLogit(df_val[columns], df_val.target)
```

```bash
                           Logit Regression Results                           
==============================================================================
Dep. Variable:                 target   No. Observations:                 4521
Model:                          Logit   Df Residuals:                     4513
Method:                           MLE   Df Model:                            7
Date:                Thu, 21 Apr 2022   Pseudo R-squ.:                  0.2621
Time:                        14:19:50   Log-Likelihood:                -1192.0
converged:                       True   LL-Null:                       -1615.5
Covariance Type:            nonrobust   LLR p-value:                1.381e-178
==============================================================================
                 coef    std err          z      P>|z|      [0.025      0.975]
------------------------------------------------------------------------------
const          2.3481      0.228     10.288      0.000       1.901       2.795
campaign      -0.0065      0.003     -2.340      0.019      -0.012      -0.001
duration      -0.0672      0.003    -21.129      0.000      -0.073      -0.061
previous      -0.0146      0.005     -3.081      0.002      -0.024      -0.005
age           -0.0104      0.002     -5.767      0.000      -0.014      -0.007
balance       -0.0033      0.001     -3.008      0.003      -0.005      -0.001
day            0.0007      0.001      0.614      0.540      -0.002       0.003
pdays          0.0012      0.004      0.272      0.785      -0.007       0.010
==============================================================================
```

**在模型中使用的是指标`WOE-Score`进行的模型拟合，因此模型参数都应为负值。上面的模型结果中存在正参数，剔除正参数指标。**

```python
columns = ['campaign', 'duration', 'previous', 'age', 'balance']
model = StatsLogit(df_val[columns], df_val.target)
```

#### 2.5 模型评估

> ROC

<center>
<img src="./img/roc.png" width="480" title="a" alt="s">
</center>

> AUC-KS

```python
metrics = RocAucKs(df_val.target, model.predict())
print(f"auc: {metrics.get('auc'):.2f} ks: {metrics.get('ks'):.2f}")

>>> auc: 0.86 ks: 0.56
```

> Recall

**在所有预测为正的样本中，预测对的比率。一般来说，cutoffpoint定的越低，召回率会越高，相应的精准度就会越低。精准度与召回率基本上是负相关的关系。**

$$
recall = \frac{TP}{TP+FN}
$$

- `TP`: 将正类预测为正类数
- `FN`: 将正类预测为负类数
- `FP`: 将负类预测为正类数
- `TN`: 将负类预测为负类数

```python

```

##### 2.5.1 模型效果评估

##### 2.5.3 模型的可解释性

> 分箱可解释性

1. 指标的各个分箱截断点应当符合一般经济含义。
2. 指标的各个分箱的分数应当相对分散，不可过渡集中。

> 模型权重可解释性

1. 理想情况下，单变量分析效果较好的指标在模型中的权重会比较大。
2. 模型的权重应当相对均衡，即每个指标都在指示一定的风险信息，指标权重很小说明该指标对模型结果的影响较小。
3. 模型的系数应当统一，在采用`WOE`值进行回归拟合时，回归系数应当都为正数，在采用`WOE-Score`值进行回归拟合时，回归系数应当都为负数。

要注意模型总体得分在全为`NAN`的情况下得多少分，这些分在总体上的位置。
2. 分箱分析要点：

#### 2.6 模型的分数映射

##### 2.6.1 权重映射

##### 2.6.2 概率映射

##### 2.6.2 评分卡分数分析与评估

> 
> lift 
> 

### 3. 总结与展望

#### 3.1 入模指标的数量

受限于逻辑回归模型的复杂度，一般单个评分卡模型的入模指标在`5`至`30`个指标不等。

#### 3.2 关于样本的切分

1. 训练集-Train：
2. 测试集-Test：
3. 时间外样本-OOT：

#### 3.2 模型结构

总模型，子模型结构

---

